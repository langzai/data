{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy\n",
    "import copy\n",
    "import math\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filePathList(dirname):\n",
    "    file_path_list = os.listdir(dirname)\n",
    "    file_path_list = list( map( lambda path : os.path.join(dirname,path) ,file_path_list))\n",
    "    return file_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fileRename(dirname):\n",
    "    file_path_list = filePathList(dirname)\n",
    "    i = 0\n",
    "    for file_name in file_path_list :\n",
    "        os.rename(file_name,os.path.join(dirname,str(i)))\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordSegment(words):\n",
    "    words = re.split('[\\s/]' , words)     #划分单词  数字中含有'.,' 不能用 '.,'分词\n",
    "    words = map( lambda word : word.strip('., ;:?\\'\\\"') , words)\n",
    "    words = [ word.lower()  for word in words if len (word) >0 ]\n",
    "    return list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWordList(dirname):\n",
    "    #用时454s\n",
    "    #word_list = []\n",
    "    #dir_list = filePathList(dirname)\n",
    "    #for file_name in dir_list:\n",
    "    #   with open(file_name) as file:\n",
    "    #       words = file.read()\n",
    "    #       words = wordSegment(words)\n",
    "    #       for word in words :\n",
    "    #           if word not in word_list :\n",
    "    #               word_list.append(word)\n",
    "    #return word_list\n",
    "    \n",
    "    #用时6.27s\n",
    "    #word_list = set()\n",
    "    #dir_list = filePathList(dirname)\n",
    "    #for file_name in dir_list:\n",
    "    #   with open(file_name) as file:\n",
    "    #       words = file.read()\n",
    "    #        words = wordSegment(words)\n",
    "    #       word_list = word_list | set(words)\n",
    "    #return word_list  \n",
    "   \n",
    "\n",
    "    word_list = {}\n",
    "    dir_list = filePathList(dirname)\n",
    "    i = 0\n",
    "    for file_name in dir_list:\n",
    "        with open(file_name) as file:\n",
    "            words = file.read()\n",
    "            words = wordSegment(words)\n",
    "            for word in words:\n",
    "                 if word not in word_list.keys():\n",
    "                        word_list[word] = i\n",
    "                        i= i + 1\n",
    "    return word_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getIndex(dirname):\n",
    "    index = {}\n",
    "    words_num = 0\n",
    "    file_list = filePathList(dirname)\n",
    "    for file_name in file_list:\n",
    "        id_file = os.path.split(file_name)[-1]\n",
    "        with open(file_name) as file:\n",
    "            words = file.read()\n",
    "            words = wordSegment(words)\n",
    "            words_num = words_num + len(words)\n",
    "            #print(words)\n",
    "            for i in range(len(words)):\n",
    "                if words[i] in index.keys() :\n",
    "                    if id_file in index[words[i]].keys():\n",
    "                        index[words[i]][id_file][0] = index[words[i]][id_file][0] + 1\n",
    "                        index[words[i]][id_file].append(i)\n",
    "                    else:\n",
    "                        index[words[i]][id_file]=[1,i]    \n",
    "                else :\n",
    "                    index[words[i]] = {id_file : [1,i]}\n",
    "    for word in index.keys():\n",
    "        word_count =0\n",
    "        for file_id in index[word].keys():\n",
    "            word_count = word_count + index[word][file_id][0]\n",
    "        index[word]['t'] = word_count  #保存每个单词出现的总次数\n",
    "    index['word_count'] = len(index.keys())\n",
    "    index['file_num'] = len(file_list) #保存总文档数\n",
    "    index['words_num'] = words_num #保存总单词数        \n",
    "    return index            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFrequencyVector(dirname):\n",
    "    frequency_vector = {}\n",
    "    dir_list = filePathList(dirname)\n",
    "    for file_name in dir_list:\n",
    "        id_file = os.path.split(file_name)[-1]\n",
    "        with open(file_name) as file:\n",
    "            words = file.read()\n",
    "            words = wordSegment(words)\n",
    "            for word in words:\n",
    "                if id_file in frequency_vector.keys():\n",
    "                    if word in frequency_vector[id_file].keys():\n",
    "                        frequency_vector[id_file][word] = frequency_vector[id_file][word] + 1\n",
    "                    else :\n",
    "                        frequency_vector[id_file][word] = 1\n",
    "                else:\n",
    "                    frequency_vector[id_file] ={word:1}     \n",
    "    return frequency_vector     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTf(frequency_vector):\n",
    "    Tf = copy.deepcopy(frequency_vector)\n",
    "    for id_file in Tf.keys():\n",
    "        for word in Tf[id_file].keys():\n",
    "            Tf[id_file][word] = 1 + math.log(Tf[id_file][word],2)\n",
    "    return Tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getIDF(index):\n",
    "    IDF = {}\n",
    "    for word in index.keys():\n",
    "        if word != 'word_count' and word !='file_num' and word != 'words_num':\n",
    "            IDF[word] = math.log(index['file_num']/(len( index[word].keys() )-1),2)\n",
    "    return IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWordWeight(Tf,IDF):\n",
    "    word_weight = {}\n",
    "    for id_file in Tf.keys():\n",
    "        word_weight[id_file] = {}\n",
    "    for id_file in Tf.keys():  \n",
    "        sum_document_weights_squares = 0\n",
    "        for word in Tf[id_file].keys():\n",
    "            word_weight[id_file][word]= Tf[id_file][word] * IDF[word]\n",
    "            sum_document_weights_squares = sum_document_weights_squares + (Tf[id_file][word] * IDF[word])**2\n",
    "        word_weight[id_file]['sum_weights_squares'] = sum_document_weights_squares\n",
    "    return word_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOptimalFileTwoWord(search_all_word,word_weight,index,num):\n",
    "    if search_all_word[0] not in index.keys() and search_all_word[1] not in index.keys() :\n",
    "        return None\n",
    "    word_position = {}\n",
    "    files = set()\n",
    "    for search_word in search_all_word :\n",
    "        #word_position[search_word] = index[search_word]\n",
    "        word_position[search_word] = index.get(search_word)\n",
    "        if search_word in index.keys():\n",
    "            files = files | set(index.get(search_word).keys())\n",
    "    #print('###',word_position,'###')\n",
    "    files = files - set('t')\n",
    "    article_relevance = {}\n",
    "    for file in files :\n",
    "        article_relevance[file] = 0\n",
    "        for search_word in search_all_word :\n",
    "            article_relevance[file] = article_relevance[file] + word_weight[file].get(search_word,0)\n",
    "      \n",
    "        if article_relevance[file] !=0 :\n",
    "            article_relevance[file] = article_relevance[file]/math.sqrt(len(search_all_word) * word_weight[file]['sum_weights_squares'])\n",
    "    article_relevance = list(article_relevance.items())\n",
    "    OptimalFile = heapq.nlargest(num,article_relevance,key = lambda x :x[1])\n",
    "    Optimal = []\n",
    "    for id_file , relevance in OptimalFile :\n",
    "        Optimal.append([id_file , relevance])\n",
    "    files = set()\n",
    "    #for i in range(len(Optimal)) :\n",
    "    if search_all_word[0] in index.keys() and search_all_word[1] in index.keys():\n",
    "        files = set(index[search_all_word[0]].keys()) & set(index[search_all_word[1]].keys()) - set('t')\n",
    "\n",
    "    for file in files :\n",
    "        for m  in range(len(Optimal)) :\n",
    "            if file == Optimal[m][0] :\n",
    "                Optimal[m][1] = Optimal[m][1] +1\n",
    "                break\n",
    "        \n",
    "    for file in files :\n",
    "        for i in index[search_all_word[0]][file][1:] :\n",
    "            isphrase = False\n",
    "            for j in index[search_all_word[1]][file][1:] :\n",
    "                if i - j == -1 :\n",
    "                    for m  in range(len(Optimal)) :\n",
    "                        if file == Optimal[m][0] :\n",
    "                            Optimal[m][1] = Optimal[m][1] +1\n",
    "                            break\n",
    "                    break\n",
    "            if isphrase :\n",
    "                break\n",
    "    Optimal = heapq.nlargest(num,Optimal,key = lambda x :x[1])\n",
    "    return Optimal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOptimalFileOneWord(search_word,word_weight,index,num):\n",
    "    if search_word not in index.keys():\n",
    "        return None\n",
    "    word_position = index[search_word]\n",
    "    #print('###',word_position)\n",
    "    files = [file for file in index[search_word].keys() if file !='t']\n",
    "    article_relevance = {}\n",
    "    for file in files :\n",
    "        if word_weight[file].get(search_word,0)!=0 :\n",
    "            article_relevance[file] = word_weight[file].get(search_word,0)/math.sqrt(word_weight[file]['sum_weights_squares'])\n",
    "        else :\n",
    "            article_relevance[file] = 0           \n",
    "    article_relevance = list(article_relevance.items())\n",
    "    OptimalFile = heapq.nlargest(num,article_relevance,key = lambda x :x[1])\n",
    "    Optimal = []\n",
    "    for id_file , relevance in OptimalFile :\n",
    "        Optimal.append([id_file , relevance])\n",
    "    return Optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOneWordContent(Optimal , index ,search_word,dirname) :\n",
    "    Optimal = copy.deepcopy(Optimal)\n",
    "    if not Optimal :\n",
    "        return None\n",
    "    search_word = search_word.lower()\n",
    "    #print(\"**************\")\n",
    "    #print(Optimal)\n",
    "    for i  in  range (len(Optimal)) :\n",
    "        Optimal[i].append(index[search_word][Optimal[i][0]])\n",
    "    \n",
    "    #print(Optimal)\n",
    "    contents = []\n",
    "    for i  in  range (len(Optimal)) :\n",
    "        position = Optimal[i][2][1];\n",
    "        if position <10 :\n",
    "            start_position = 0\n",
    "        else :\n",
    "            start_position = position - 10\n",
    "        f = open(os.path.join(dirname,str(Optimal[i][0])),'r')\n",
    "        words = f.read()\n",
    "        f.close()\n",
    "        words = wordSegment(words)\n",
    "        j = 0\n",
    "        content = ''\n",
    "        while start_position < len(words) and j <20 :\n",
    "            content = content + words[start_position] + ' '\n",
    "            start_position = start_position + 1\n",
    "            j = j+1\n",
    "        contents.append([Optimal[i][0],Optimal[i][1],content])\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTwoWordContent(Optimal , index ,search_all_word,dirname) :\n",
    "    if not Optimal :\n",
    "        return None\n",
    "    contents = []\n",
    "    for i in range(len(Optimal)) :\n",
    "        if Optimal[i][1] > 2 :\n",
    "            contents.append(getOneWordContent([Optimal[i] ], index ,search_all_word[0],dirname))\n",
    "        elif Optimal[i][1] >1 :\n",
    "            content = getOneWordContent([Optimal[i]] , index ,search_all_word[0],dirname)\n",
    "            #print(Optimal[i][0])\n",
    "            if search_all_word[1] not in content[0][2] :\n",
    "                content[0][2] = content[0][2] + '...' + getOneWordContent([Optimal[i]] , index ,search_all_word[1],dirname)[0][2]\n",
    "            contents.append(content)\n",
    "        else :\n",
    "            if search_all_word[0] in index.keys() and Optimal[i][0] in index[search_all_word[0]].keys() and search_all_word[0] !='word_count' and search_all_word[0] !='file_num'  and search_all_word[0] !='words_num':\n",
    "                #try :\n",
    "                    contents.append(getOneWordContent([Optimal[i]] , index ,search_all_word[0],dirname))\n",
    "                #except :\n",
    "                    #print(([Optimal[i]] , index ,search_all_word[0],dirname))\n",
    "                    pass\n",
    "            else :\n",
    "                contents.append(getOneWordContent([Optimal[i]] , index ,search_all_word[1],dirname))\n",
    "                #pass\n",
    "    return contents\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
